{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GprysbY7ObW-"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Read the input image\n",
        "image = cv2.imread('/content/drive/MyDrive/Notes/Year4/Fall/AER850/AER850_Project3_Data/motherboard_image.JPEG')\n",
        "\n",
        "# Convert the image to grayscale\n",
        "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Apply thresholding to the image\n",
        "_, thresholded = cv2.threshold(gray_image, 110, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "# Invert mask\n",
        "inverted_mask=cv2.bitwise_not(thresholded)\n",
        "\n",
        "# Perform edge detection using contour detection\n",
        "contours, _ = cv2.findContours(inverted_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "# Find the largest contour (assuming it's the motherboard)\n",
        "largest_contour = max(contours, key=cv2.contourArea)\n",
        "image_with_contours = image.copy()\n",
        "\n",
        "# Create an empty mask to extract the board\n",
        "mask = np.zeros_like(gray_image)\n",
        "cv2.drawContours(mask, [largest_contour], -1, (255, 255, 255), thickness=cv2.FILLED)\n",
        "cv2.drawContours(image_with_contours, [largest_contour], -1, (0, 255, 0), 2)\n",
        "\n",
        "# Extract the motherboard from the background\n",
        "board_extracted = cv2.bitwise_and(image, image, mask=mask)\n",
        "\n",
        "#Image resizing\n",
        "target_width, target_height = int(2172/2.5),int(2896/2.5)\n",
        "resized_image = cv2.resize(image, (target_width, target_height))\n",
        "\n",
        "# Display the results\n",
        "cv2_imshow(resized_image)\n",
        "cv2_imshow(inverted_mask)\n",
        "cv2_imshow(board_extracted)\n",
        "cv2_imshow(image_with_contours)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZkelbf1PjbX"
      },
      "outputs": [],
      "source": [
        "# Install the ultralytics package from PyPI\n",
        "!pip install ultralytics\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO('yolov8n.pt')  # build a new model from YAML\n",
        "\n",
        "# Train the model\n",
        "results = model.train(data='/content/drive/MyDrive/Notes/Year4/Fall/AER850/AER850_Project3_Data/data.yaml', epochs=150, imgsz=1000, batch=4, name='AER850_Proj3_Model_150Epoch')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fe-9DgbbIkV7"
      },
      "outputs": [],
      "source": [
        "local_model = YOLO(\"/content/runs/detect/AER850_Proj3_Model/weights/best.pt\")\n",
        "results = local_model.predict('/content/drive/MyDrive/Notes/Year4/Fall/AER850/AER850_Project3_Data/evaluation/rasppi.jpg')\n",
        "print(results)\n",
        "\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "annotated_frame = results[0].plot()\n",
        "scale=0.25\n",
        "\n",
        "# Display the annotated frame\n",
        "cv2_imshow(annotated_frame)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}